#!/bin/bash

# this script gets executed once for each gpu on every node of an allocation;
# in our case we use the provided COMPUTE_* env variables to construct a 
# distributed TensorFlow cluster definition that is passed to the base command
# through the TF_CONFIG env variable

set -o pipefail

# activating standard TensorFlow Python virtual environment
source /usr/local/tensorflow/bin/activate

# the standard script to execute
base_cmd="./.run"

# reading the comma separated node list into array "nodes"
IFS=',' read -r -a nodes <<< "$COMPUTE_NODES"
# keep fist node for convenience
first=${nodes[0]}
# hostname for debugging
hostname=`hostname`
# log timestamp prefix
time_format='[%Y-%m-%d %H:%M:%.S]'
sub_processes=1

# defining all cluster ports in a way that avoids collisions with other cluster allocations
# (that could eventually get scheduled on the same node)
((port_base=10000 + (COMPUTE_JOB_NUMBER * 100) % 50000))

# create comma separated list of ps's (there is only one ps)
((ps_port=port_base))
ps_hosts="$first:$ps_port"

# create comma separated list of masters (there is only one master)
((master_port=ps_port + 1))
master_hosts="$first:$master_port"

# create comma separated list of workers
((worker_port=ps_port + 1))
for node in "${nodes[@]}"; do
    for gpu_index in $(seq 1 $((COMPUTE_GPUS_PER_NODE))); do
        if ((node != first)) || ((gpu_index != 1)); then
            worker_hosts[$worker_port]="$node:$worker_port"
        fi
        ((worker_port=worker_port + 1))
    done
done
worker_hosts=$(printf ",\"%s\"" "${worker_hosts[@]}")
worker_hosts=${worker_hosts:1}

# create cluster spec json
cluster_spec=$(printf "\"cluster\": {\"ps\": [\"%s\"], \"master\": [\"%s\"], \"worker\": [%s]}" "$ps_hosts" "$master_hosts" "$worker_hosts")

# create environment spec json
environment_spec="\"environment\": \"cloud\""

# create ps task spec json
ps_spec="\"task\": {\"type\": \"ps\", \"index\": 0}"

# create master task spec json
master_spec="\"task\": {\"type\": \"master\", \"index\": 0}"

# helpful for debugging potential networking issues
echo "Starting allocated node no. $COMPUTE_NODE_INDEX gpu no. $COMPUTE_GPU_INDEX on $hostname of cluster (ps: $first:$ps_port, master: $master_hosts, workers: $worker_hosts) ..."

# starting the parameter server side by side with master on the first node;
# so for the moment we only run one ps per allocation
if ((COMPUTE_NODE_INDEX == 0)) && ((COMPUTE_GPU_INDEX == 0)); then
    # CUDA_VISIBLE_DEVICES="" - as the parameter server does not require a GPU;
    # the GPU would be shared with the workers on the same machine;
    # it turned out that this would drastically reduce available GPU memory
    sub_processes=2
    logfile=../ps_$COMPUTE_NODE_INDEX.log
    touch $logfile #environment guarantees existence for "tail -f *.log"
    tf_config=$(printf "{%s, %s, %s}" "$cluster_spec" "$environment_spec" "$ps_spec")
    export TF_CONFIG=$tf_config
    CUDA_VISIBLE_DEVICES="" $base_cmd "$@" 2>&1 | ts "$time_format [ps     $COMPUTE_NODE_INDEX]" >$logfile &
fi

if ((COMPUTE_NODE_INDEX == 0)) && ((COMPUTE_GPU_INDEX == 0)); then
    # starting the master side by side with parameter server on the first node
    logfile=../master_$COMPUTE_NODE_INDEX.log
    touch $logfile # guarantees existence for "tail -f *.log"
    tf_config=$(printf "{%s, %s, %s}" "$cluster_spec" "$environment_spec" "$master_spec")
    export TF_CONFIG=$tf_config
    CUDA_VISIBLE_DEVICES="$COMPUTE_GPU_INDEX" $base_cmd "$@" 2>&1 | ts "$time_format [master $COMPUTE_NODE_INDEX]" >$logfile &
else
    # create worker identifier, its index in worker_hosts
    worker_id=$((COMPUTE_NODE_INDEX * COMPUTE_GPUS_PER_NODE + COMPUTE_GPU_INDEX - 1))
    # starting the worker
    logfile=../worker_$worker_id.log
    touch $logfile # guarantees existence for "tail -f *.log"
    worker_spec=$(printf "\"task\": {\"type\": \"worker\", \"index\": %d}" $worker_id)
    tf_config=$(printf "{%s, %s, %s}" "$cluster_spec" "$environment_spec" "$worker_spec")
    export TF_CONFIG=$tf_config
    CUDA_VISIBLE_DEVICES="$COMPUTE_GPU_INDEX" $base_cmd "$@" 2>&1 | ts "$time_format [worker $worker_id]" >$logfile &
fi

for index in $(seq 1 $sub_processes);
do
  # "wait -n" waits for any sub-process to exit
  # doing this sub_processes times will wait for all sub-processes to finish
  # in case of any sub-process failing, it will exit immediately
  wait -n
  code=$?
  if ((code > 0)); then
    echo "One compute process failed with exit code $code."
    exit $code
  else
    echo "One compute process succeeded."
  fi
done
